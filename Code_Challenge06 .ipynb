{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67fe8dd-d06c-4dba-a356-312b5d03cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e740d5-e8ee-4bda-8d43-3511f57aaa51",
   "metadata": {},
   "source": [
    "# Import and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e30b47d-d10f-4260-ad38-db6fdfc721c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = pd.read_csv('mnist_train_small .csv',delimiter=',')\n",
    "\n",
    "data_np = data.to_numpy()\n",
    "labels = data_np[:, 0]\n",
    "data = data_np[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04e97c4a-1d91-4966-905f-058e1b50c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c87b9b-587d-45a5-9e82-3cc2ee2f7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf124dfb-df27-40f5-ae8c-bc5bbc4d4ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test groups using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10b5554-5bc0-4a0f-9a40-04d5e8a61022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: convert to tensor\n",
    "dataT   = torch.tensor( dataNorm ).float()\n",
    "labelsT = torch.tensor( labels ).long() # long = int64\n",
    "\n",
    "# Step 2: use scikitlearn to split the data\n",
    "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
    "\n",
    "\n",
    "# Step 3: convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# Step 4: translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29da9b4b-4f4e-4a24-aa30-f80dcbc1453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83a05977-0a1c-4b15-b2c0-419e08c08c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheMNISTNet(nUnits, nLayers):\n",
    "    class mnistNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            # create dictionary to store the layers\n",
    "            self.layers = nn.ModuleDict()\n",
    "            self.nLayers = nLayers  \n",
    "            \n",
    "            ### input layer\n",
    "            self.layers['input'] = nn.Linear(784, nUnits)\n",
    "            \n",
    "            ### hidden layers\n",
    "            for i in range(nLayers):\n",
    "                self.layers[f'hidden{i}'] = nn.Linear(nUnits, nUnits)\n",
    "            ### output layer\n",
    "            self.layers['output'] = nn.Linear(nUnits, 10)\n",
    "            \n",
    "        # forward pass reste identique\n",
    "        def forward(self, x):\n",
    "            # input layer\n",
    "            x = F.relu(self.layers['input'](x))\n",
    "            # hidden layers\n",
    "            for i in range(self.nLayers):\n",
    "                x = F.relu(self.layers[f'hidden{i}'](x))\n",
    "            # return output layer\n",
    "            x = self.layers['output'](x)\n",
    "            return torch.log_softmax(x, axis=1)\n",
    "    \n",
    "    # create the model instance\n",
    "    net = mnistNet()\n",
    "    \n",
    "    # loss function\n",
    "    lossfun = nn.NLLLoss()\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=.01)\n",
    "    return net, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6d0772-892c-42ed-977e-99c242540896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(mnistNet(\n",
       "   (layers): ModuleDict(\n",
       "     (input): Linear(in_features=784, out_features=12, bias=True)\n",
       "     (hidden0): Linear(in_features=12, out_features=12, bias=True)\n",
       "     (hidden1): Linear(in_features=12, out_features=12, bias=True)\n",
       "     (output): Linear(in_features=12, out_features=10, bias=True)\n",
       "   )\n",
       " ),\n",
       " NLLLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.01\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate an instance of the model and inspect it\n",
    "nUnitsPerLayer = 12\n",
    "nLayers = 2\n",
    "net = createTheMNISTNet(nUnitsPerLayer,nLayers)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea443a7a-4eed-4ab1-97e5-2b0c321dd76e",
   "metadata": {},
   "source": [
    "# Create a function that trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c75b554f-0e51-47d9-92ba-f091881cb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "def function2trainTheModel(nUnits, nLayers):\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 500\n",
    "  \n",
    "  # create a new model\n",
    "  net,lossfun,optimizer = createTheMNISTNet(nUnits, nLayers)\n",
    "\n",
    "  # initialize losses\n",
    "  losses    = torch.zeros(numepochs)\n",
    "  trainAcc  = []\n",
    "  testAcc   = []\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    batchAcc  = []\n",
    "    batchLoss = []\n",
    "    for X,y in train_loader:\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossfun(yHat,y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "\n",
    "      # compute accuracy\n",
    "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
    "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
    "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
    "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
    "    # end of batch loop...\n",
    "\n",
    "    # now that we've trained through the batches, get their average training accuracy\n",
    "    trainAcc.append( np.mean(batchAcc) )\n",
    "\n",
    "    # and get average losses across the batches\n",
    "    losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "    # test accuracy\n",
    "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
    "    yHat = net(X)\n",
    "      \n",
    "    # compare the following really long line of code to the training accuracy lines\n",
    "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
    "\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainAcc,testAcc,losses,net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac2978aa-3b3c-4f00-81ce-5cdd4f3ad9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de6fc006-4082-41f8-b518-515e09b92650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished units 1/5 and layers 1/3\n",
      "Finished units 1/5 and layers 2/3\n",
      "Finished units 1/5 and layers 3/3\n",
      "Finished units 2/5 and layers 1/3\n",
      "Finished units 2/5 and layers 2/3\n",
      "Finished units 2/5 and layers 3/3\n",
      "Finished units 3/5 and layers 1/3\n",
      "Finished units 3/5 and layers 2/3\n",
      "Finished units 3/5 and layers 3/3\n",
      "Finished units 4/5 and layers 1/3\n",
      "Finished units 4/5 and layers 2/3\n",
      "Finished units 4/5 and layers 3/3\n",
      "Finished units 5/5 and layers 1/3\n",
      "Finished units 5/5 and layers 2/3\n",
      "Finished units 5/5 and layers 3/3\n"
     ]
    }
   ],
   "source": [
    "# define the model parameters\n",
    "numlayers = range(1,4)         # number of hidden layers\n",
    "numunits  = np.arange(50,251,50) # units per hidden layer\n",
    "\n",
    "# initialize output matrices\n",
    "accuracies  = np.zeros((2, len(numunits),len(numlayers)))\n",
    "\n",
    "# number of training epochs\n",
    "numepochs = 60\n",
    "\n",
    "# start the experiment!\n",
    "for unitidx in range(len(numunits)):\n",
    "  for layeridx in range(len(numlayers)):\n",
    "\n",
    "    # create and train a fresh model\n",
    "    trainAcc,testAcc,losses,net = function2trainTheModel(numunits[unitidx],numlayers[layeridx])\n",
    "\n",
    "    # store the results (average of final 5 epochs)\n",
    "    accuracies[0,unitidx,layeridx] = np.mean(trainAcc[-5:])\n",
    "    accuracies[1,unitidx,layeridx] = np.mean(testAcc[-5:])\n",
    "\n",
    "    # print a friendly status message\n",
    "    print(f'Finished units {unitidx+1}/{len(numunits)} and layers {layeridx+1}/{len(numlayers)}') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
